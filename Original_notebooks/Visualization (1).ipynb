{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import wandb\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:19.006618Z",
          "iopub.execute_input": "2025-05-19T18:25:19.007134Z",
          "iopub.status.idle": "2025-05-19T18:25:27.445976Z",
          "shell.execute_reply.started": "2025-05-19T18:25:19.007109Z",
          "shell.execute_reply": "2025-05-19T18:25:27.445299Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNHtlNAYNyPi",
        "outputId": "2239bcd1-782d-4693-ca85-f89b855a9910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qq https://ektype.in/fontshost/Anek_Devanagari.zip\n",
        "!unzip Anek_Devanagari.zip \"static/AnekDevanagari/*\"\n",
        "!cp -r static/AnekDevanagari /usr/share/fonts/truetype"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:27.44717Z",
          "iopub.execute_input": "2025-05-19T18:25:27.447803Z",
          "iopub.status.idle": "2025-05-19T18:25:28.732776Z",
          "shell.execute_reply.started": "2025-05-19T18:25:27.447781Z",
          "shell.execute_reply": "2025-05-19T18:25:28.731666Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmaLcadMNyPk",
        "outputId": "8371cf8c-a268-4e19-8a34-75ec7da98927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Anek_Devanagari.zip\n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-Thin.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-ExtraLight.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-Light.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-Regular.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-Medium.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-SemiBold.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-Bold.ttf  \n",
            "  inflating: static/AnekDevanagari/AnekDevanagari-ExtraBold.ttf  \n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "font_path = '/usr/share/fonts/truetype/AnekDevanagari/AnekDevanagari-Regular.ttf'\n",
        "font_prop = fm.FontProperties(fname=font_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:28.733946Z",
          "iopub.execute_input": "2025-05-19T18:25:28.734256Z",
          "iopub.status.idle": "2025-05-19T18:25:28.738736Z",
          "shell.execute_reply.started": "2025-05-19T18:25:28.734223Z",
          "shell.execute_reply": "2025-05-19T18:25:28.738012Z"
        },
        "id": "EOQtTIvMNyPl"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar\n",
        "\n",
        "# Data paths\n",
        "train_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_path = \"dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(train_path, delimiter='\\t', names=['hi', 'en', '_'])\n",
        "val_df = pd.read_csv(val_path, delimiter='\\t', names=['hi', 'en', '_'])\n",
        "test_df = pd.read_csv(test_path, delimiter='\\t', names=['hi', 'en', '_'])\n",
        "\n",
        "print(f\"Train samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "print(f\"Test samples: {len(test_df)}\")\n",
        "\n",
        "# Check max sequence lengths\n",
        "src_max_len = max([len(str(text)) for text in train_df['en']])\n",
        "tgt_max_len = max([len(str(text)) for text in train_df['hi']])\n",
        "print(f\"Max source sequence length: {src_max_len}\")\n",
        "print(f\"Max target sequence length: {tgt_max_len}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:28.740308Z",
          "iopub.execute_input": "2025-05-19T18:25:28.740567Z",
          "iopub.status.idle": "2025-05-19T18:25:37.770932Z",
          "shell.execute_reply.started": "2025-05-19T18:25:28.74055Z",
          "shell.execute_reply": "2025-05-19T18:25:37.77003Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI2z2EGRNyPm",
        "outputId": "7dbda383-3e90-48e3-e02a-7c9bfca68777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 10:35:45--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 74.125.137.207, 142.250.101.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   195MB/s    in 9.9s    \n",
            "\n",
            "2025-05-21 10:35:55 (194 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n",
            "Train samples: 44204\n",
            "Validation samples: 4358\n",
            "Test samples: 4502\n",
            "Max source sequence length: 20\n",
            "Max target sequence length: 19\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocab(texts, special_tokens=True):\n",
        "    chars = set()\n",
        "    for text in texts:\n",
        "        for char in str(text):\n",
        "            chars.add(char)\n",
        "\n",
        "    # Create vocabulary dictionary\n",
        "    if special_tokens:\n",
        "        vocab = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
        "    else:\n",
        "        vocab = {}\n",
        "\n",
        "    for i, char in enumerate(sorted(list(chars))):\n",
        "        vocab[char] = i + 4\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def text_to_indices(text, vocab):\n",
        "    indices = [vocab['<SOS>']]\n",
        "    for char in str(text):\n",
        "        if char in vocab:\n",
        "            indices.append(vocab[char])\n",
        "        elif char.lower() in vocab:\n",
        "            indices.append(vocab[char.lower()])\n",
        "        else:\n",
        "            indices.append(vocab['<UNK>'])\n",
        "    indices.append(vocab['<EOS>'])\n",
        "    return indices\n",
        "\n",
        "# Create vocabularies\n",
        "src_vocab = create_vocab(train_df['en'])\n",
        "tgt_vocab = create_vocab(train_df['hi'])\n",
        "\n",
        "# Create reverse mappings for visualization\n",
        "idx2src = {idx: char for char, idx in src_vocab.items()}\n",
        "idx2tgt = {idx: char for char, idx in tgt_vocab.items()}\n",
        "\n",
        "print(f\"Source vocabulary size: {len(src_vocab)}\")\n",
        "print(f\"Target vocabulary size: {len(tgt_vocab)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:37.772035Z",
          "iopub.execute_input": "2025-05-19T18:25:37.772326Z",
          "iopub.status.idle": "2025-05-19T18:25:37.852312Z",
          "shell.execute_reply.started": "2025-05-19T18:25:37.772292Z",
          "shell.execute_reply": "2025-05-19T18:25:37.851611Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVstNQysNyPm",
        "outputId": "25f2eb5f-3c50-464b-f4fb-4734e13c8ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source vocabulary size: 30\n",
            "Target vocabulary size: 67\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, dataframe, src_vocab, tgt_vocab):\n",
        "        self.dataframe = dataframe\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.dataframe.iloc[idx]['en']\n",
        "        tgt_text = self.dataframe.iloc[idx]['hi']\n",
        "\n",
        "        src_indices = text_to_indices(src_text, self.src_vocab)\n",
        "        tgt_indices = text_to_indices(tgt_text, self.tgt_vocab)\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src, tgt in batch:\n",
        "        # Safety check for index bounds\n",
        "        src = torch.clamp(src, 0, len(src_vocab)-1)\n",
        "        tgt = torch.clamp(tgt, 0, len(tgt_vocab)-1)\n",
        "\n",
        "        # Pad or truncate to max lengths\n",
        "        src = src[:20]  # Max source length is 20\n",
        "        tgt = tgt[:19]  # Max target length is 19\n",
        "\n",
        "        src_batch.append(src)\n",
        "        tgt_batch.append(tgt)\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=src_vocab['<PAD>'])\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=tgt_vocab['<PAD>'])\n",
        "\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:37.852968Z",
          "iopub.execute_input": "2025-05-19T18:25:37.853219Z",
          "iopub.status.idle": "2025-05-19T18:25:37.864898Z",
          "shell.execute_reply.started": "2025-05-19T18:25:37.853196Z",
          "shell.execute_reply": "2025-05-19T18:25:37.864184Z"
        },
        "id": "ZkUAfK0TNyPn"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_vocab_size, embedding_dim, hidden_dim, num_layers, dropout, cell_type):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_vocab_size, embedding_dim)\n",
        "        self.cell_type = cell_type.lower()\n",
        "\n",
        "        if self.cell_type == \"lstm\":\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                              dropout=dropout if num_layers > 1 else 0, batch_first=True)\n",
        "        elif self.cell_type == \"gru\":\n",
        "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                             dropout=dropout if num_layers > 1 else 0, batch_first=True)\n",
        "        else:  # rnn\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                             dropout=dropout if num_layers > 1 else 0, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Apply weight initialization\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data)\n",
        "            elif 'bias' in name:\n",
        "                param.data.fill_(0)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src: [batch_size, src_len]\n",
        "        embedded = self.dropout(self.embedding(src))  # [batch_size, src_len, emb_dim]\n",
        "\n",
        "        if self.cell_type == \"lstm\":\n",
        "            outputs, (hidden, cell) = self.rnn(embedded)\n",
        "            return outputs, hidden, cell\n",
        "        else:\n",
        "            outputs, hidden = self.rnn(embedded)\n",
        "            return outputs, hidden, None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:37.865554Z",
          "iopub.execute_input": "2025-05-19T18:25:37.866702Z",
          "iopub.status.idle": "2025-05-19T18:25:39.505829Z",
          "shell.execute_reply.started": "2025-05-19T18:25:37.866676Z",
          "shell.execute_reply": "2025-05-19T18:25:39.504695Z"
        },
        "id": "lIIakP7DNyPo"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, hidden_dim, num_layers, dropout, cell_type):\n",
        "        super().__init__()\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(output_vocab_size, embedding_dim)\n",
        "        self.cell_type = cell_type.lower()\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.attention_combine = nn.Linear(hidden_dim + embedding_dim, embedding_dim)\n",
        "\n",
        "        # RNN layer\n",
        "        if cell_type == \"lstm\":\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                              dropout=dropout if num_layers > 1 else 0, batch_first=True)\n",
        "        elif cell_type == \"gru\":\n",
        "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                             dropout=dropout if num_layers > 1 else 0, batch_first=True)\n",
        "        else:  # rnn\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                             dropout=dropout if num_layers > 1 else 0, batch_first=True)\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Apply weight initialization\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data)\n",
        "            elif 'bias' in name:\n",
        "                param.data.fill_(0)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        # input: [batch_size]\n",
        "        # hidden: [num_layers, batch_size, hidden_dim]\n",
        "        # encoder_outputs: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
        "        embedded = self.dropout(self.embedding(input))  # [batch_size, 1, emb_dim]\n",
        "\n",
        "        # Calculate attention weights\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        src_len = encoder_outputs.size(1)\n",
        "\n",
        "        # Use the last layer of hidden state for attention\n",
        "        attn_hidden = hidden[-1].unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
        "\n",
        "        # Repeat for each encoder output\n",
        "        attn_hidden = attn_hidden.repeat(1, src_len, 1)  # [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # Concatenate encoder outputs and hidden state\n",
        "        energy = torch.cat((encoder_outputs, attn_hidden), dim=2)  # [batch_size, src_len, 2*hidden_dim]\n",
        "        energy = self.attention(energy)  # [batch_size, src_len, hidden_dim]\n",
        "        energy = torch.tanh(energy)\n",
        "\n",
        "        # Calculate attention weights\n",
        "        attn_weights = torch.sum(energy, dim=2)  # [batch_size, src_len]\n",
        "        attn_weights = F.softmax(attn_weights, dim=1).unsqueeze(1)  # [batch_size, 1, src_len]\n",
        "\n",
        "        # Apply attention weights to encoder outputs\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)  # [batch_size, 1, hidden_dim]\n",
        "\n",
        "        # Combine embedded input and context vector\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)  # [batch_size, 1, emb_dim + hidden_dim]\n",
        "        rnn_input = self.attention_combine(rnn_input)  # [batch_size, 1, emb_dim]\n",
        "\n",
        "        # Pass through RNN\n",
        "        if self.cell_type == \"lstm\":\n",
        "            output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "        else:\n",
        "            output, hidden = self.rnn(rnn_input, hidden)\n",
        "            cell = None\n",
        "\n",
        "        # Generate output\n",
        "        prediction = self.fc_out(output.squeeze(1))  # [batch_size, output_vocab_size]\n",
        "\n",
        "        return prediction, hidden, cell, attn_weights"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:39.506778Z",
          "iopub.execute_input": "2025-05-19T18:25:39.507079Z",
          "iopub.status.idle": "2025-05-19T18:25:41.2485Z",
          "shell.execute_reply.started": "2025-05-19T18:25:39.507055Z",
          "shell.execute_reply": "2025-05-19T18:25:41.247599Z"
        },
        "id": "CSvYByHiNyPp"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(\n",
        "            config['input_vocab_size'],\n",
        "            config['embedding_dim'],\n",
        "            config['hidden_dim'],\n",
        "            config['num_encoding_layers'],\n",
        "            config['dropout'],\n",
        "            config['cell_type']\n",
        "        )\n",
        "        self.decoder = AttentionDecoder(\n",
        "            config['output_vocab_size'],\n",
        "            config['embedding_dim'],\n",
        "            config['hidden_dim'],\n",
        "            config['num_decoding_layers'],\n",
        "            config['dropout'],\n",
        "            config['cell_type']\n",
        "        )\n",
        "        self.device = config.get('device', device)\n",
        "        self.teacher_forcing_ratio = config.get('teacher_forcing_ratio', 0.5)\n",
        "        self.cell_type = config['cell_type'].lower()\n",
        "        self.config = config\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing=1):\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_vocab_size\n",
        "\n",
        "        # Tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # Tensor to store attention weights\n",
        "        attentions = torch.zeros(batch_size, trg_len, src.shape[1]).to(self.device)\n",
        "\n",
        "        # Encode source sequence\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        # Adjust hidden state dimensions if needed\n",
        "        enc_layers = self.config['num_encoding_layers']\n",
        "        dec_layers = self.config['num_decoding_layers']\n",
        "        hidden_size = self.config['hidden_dim']\n",
        "\n",
        "        if enc_layers != dec_layers:\n",
        "            if self.cell_type != 'lstm':\n",
        "                # Case 1: Encoder has more layers - take only what we need\n",
        "                if enc_layers > dec_layers:\n",
        "                    hidden = hidden[:dec_layers]\n",
        "                # Case 2: Decoder has more layers - pad with zeros\n",
        "                else:\n",
        "                    padding = torch.zeros(dec_layers - enc_layers, batch_size, hidden_size).to(self.device)\n",
        "                    hidden = torch.cat([hidden, padding], dim=0)\n",
        "            else:  # LSTM case\n",
        "                if enc_layers > dec_layers:\n",
        "                    hidden = hidden[:dec_layers]\n",
        "                    cell = cell[:dec_layers]\n",
        "                else:\n",
        "                    padding = torch.zeros(dec_layers - enc_layers, batch_size, hidden_size).to(self.device)\n",
        "                    hidden = torch.cat([hidden, padding], dim=0)\n",
        "                    cell = torch.cat([cell, padding], dim=0)\n",
        "\n",
        "        # First input to decoder is <SOS> token\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # Get decoder output\n",
        "            output, hidden, cell, attn_weights = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "\n",
        "            # Store prediction and attention weights\n",
        "            outputs[:, t, :] = output\n",
        "            attentions[:, t, :] = attn_weights.squeeze(1)\n",
        "\n",
        "            # Teacher forcing\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio * teacher_forcing\n",
        "\n",
        "            # Get highest predicted token\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            # Next input is either ground truth or predicted token\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs, attentions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:41.249478Z",
          "iopub.execute_input": "2025-05-19T18:25:41.249762Z",
          "iopub.status.idle": "2025-05-19T18:25:42.975275Z",
          "shell.execute_reply.started": "2025-05-19T18:25:41.249738Z",
          "shell.execute_reply": "2025-05-19T18:25:42.974271Z"
        },
        "id": "A84O7iWjNyPq"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # For exact match accuracy\n",
        "    exact_match_correct = 0\n",
        "    exact_match_total = 0\n",
        "\n",
        "    # For character-level accuracy\n",
        "    char_correct = 0\n",
        "    char_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg, 0)  # Turn off teacher forcing\n",
        "\n",
        "            # For loss calculation\n",
        "            output_dim = output.shape[-1]\n",
        "            output_flat = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg_flat = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output_flat, trg_flat)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            predictions = output.argmax(dim=2)\n",
        "\n",
        "            # Calculate exact match and character-level accuracy\n",
        "            for i in range(len(predictions)):\n",
        "                pred_seq = predictions[i, 1:].cpu().numpy()  # Skip <SOS>\n",
        "                target_seq = trg[i, 1:].cpu().numpy()  # Skip <SOS>\n",
        "\n",
        "                # Get valid sequence (remove padding)\n",
        "                valid_length = (target_seq != tgt_vocab['<PAD>']).sum()\n",
        "                pred_clean = pred_seq[:valid_length]\n",
        "                target_clean = target_seq[:valid_length]\n",
        "\n",
        "                # Check exact match\n",
        "                if np.array_equal(pred_clean, target_clean):\n",
        "                    exact_match_correct += 1\n",
        "                exact_match_total += 1\n",
        "\n",
        "                # Calculate character-level accuracy\n",
        "                for j in range(valid_length):\n",
        "                    if pred_seq[j] == target_seq[j]:\n",
        "                        char_correct += 1\n",
        "                    char_total += 1\n",
        "\n",
        "    # Calculate metrics\n",
        "    exact_match_accuracy = exact_match_correct / exact_match_total if exact_match_total > 0 else 0\n",
        "    char_accuracy = char_correct / char_total if char_total > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'loss': epoch_loss / len(dataloader),\n",
        "        'exact_match_accuracy': exact_match_accuracy,\n",
        "        'char_accuracy': char_accuracy\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:44.68102Z",
          "iopub.execute_input": "2025-05-19T18:25:44.681326Z",
          "iopub.status.idle": "2025-05-19T18:25:46.771186Z",
          "shell.execute_reply.started": "2025-05-19T18:25:44.681296Z",
          "shell.execute_reply": "2025-05-19T18:25:46.770363Z"
        },
        "id": "UTKzj-aKNyPs"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, src_vocab, tgt_vocab, idx2tgt, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Convert to indices and add <SOS> and <EOS>\n",
        "    indices = text_to_indices(sentence, src_vocab)\n",
        "    src_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)\n",
        "\n",
        "    # Get encoder outputs\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    # Adjust hidden state dimensions if needed\n",
        "    enc_layers = model.config['num_encoding_layers']\n",
        "    dec_layers = model.config['num_decoding_layers']\n",
        "    hidden_size = model.config['hidden_dim']\n",
        "\n",
        "    if enc_layers != dec_layers:\n",
        "        batch_size = 1  # Since we're translating one sentence\n",
        "        if model.cell_type != 'lstm':\n",
        "            if enc_layers > dec_layers:\n",
        "                hidden = hidden[:dec_layers]\n",
        "            else:\n",
        "                padding = torch.zeros(dec_layers - enc_layers, batch_size, hidden_size).to(device)\n",
        "                hidden = torch.cat([hidden, padding], dim=0)\n",
        "        else:  # LSTM case\n",
        "            if enc_layers > dec_layers:\n",
        "                hidden = hidden[:dec_layers]\n",
        "                cell = cell[:dec_layers]\n",
        "            else:\n",
        "                padding = torch.zeros(dec_layers - enc_layers, batch_size, hidden_size).to(device)\n",
        "                hidden = torch.cat([hidden, padding], dim=0)\n",
        "                cell = torch.cat([cell, padding], dim=0)\n",
        "\n",
        "    # Start with <SOS> token\n",
        "    trg_idx = [tgt_vocab['<SOS>']]\n",
        "    attentions = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_idx[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell, attn_weights = model.decoder(trg_tensor, hidden, cell, encoder_outputs)\n",
        "\n",
        "        # Store attention weights\n",
        "        attentions.append(attn_weights.squeeze().cpu().numpy())\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "\n",
        "        # Stop if <EOS> token\n",
        "        if pred_token == tgt_vocab['<EOS>']:\n",
        "            break\n",
        "\n",
        "        trg_idx.append(pred_token)\n",
        "\n",
        "    # Convert indices to characters\n",
        "    trg_tokens = [idx2tgt[i] for i in trg_idx if i not in [tgt_vocab['<SOS>'], tgt_vocab['<EOS>'], tgt_vocab['<PAD>'], tgt_vocab['<UNK>']]]\n",
        "\n",
        "    return ''.join(trg_tokens), attentions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T18:25:46.772143Z",
          "iopub.execute_input": "2025-05-19T18:25:46.772428Z",
          "iopub.status.idle": "2025-05-19T18:25:49.896736Z",
          "shell.execute_reply.started": "2025-05-19T18:25:46.772387Z",
          "shell.execute_reply": "2025-05-19T18:25:49.8958Z"
        },
        "id": "LD6UroyrNyPs"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_connectivity(model, src_text, src_vocab, tgt_vocab, idx2tgt, max_len=50):\n",
        "    \"\"\"\n",
        "    Compute gradient-based connectivity between input and output characters.\n",
        "\n",
        "    Args:\n",
        "        model: The Seq2Seq model\n",
        "        src_text: Source text (Latin characters)\n",
        "        src_vocab: Source vocabulary mapping\n",
        "        tgt_vocab: Target vocabulary mapping\n",
        "        idx2tgt: Mapping from indices to target characters\n",
        "        max_len: Maximum generation length\n",
        "\n",
        "    Returns:\n",
        "        translation: Generated translation\n",
        "        connectivity: Matrix of gradient magnitudes [tgt_len, src_len]\n",
        "    \"\"\"\n",
        "    # Step 2.1: Set model to train mode to enable gradient computation\n",
        "    model.train()\n",
        "\n",
        "    # Step 2.2: Convert source text to indices\n",
        "    src_indices = text_to_indices(src_text, src_vocab)\n",
        "    src_tensor = torch.LongTensor(src_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    # Step 2.3: Get embeddings with gradient tracking\n",
        "    # This is the input we'll compute gradients with respect to\n",
        "    src_emb = model.encoder.embedding(src_tensor)\n",
        "    src_emb.retain_grad()  # Keep gradients for this tensor\n",
        "\n",
        "    # Step 2.4: Get encoder outputs\n",
        "    if model.cell_type == \"lstm\":\n",
        "        encoder_outputs, (hidden, cell) = model.encoder.rnn(src_emb)\n",
        "    else:  # GRU or RNN\n",
        "        encoder_outputs, hidden = model.encoder.rnn(src_emb)\n",
        "        cell = None\n",
        "\n",
        "    # Step 2.5: Adjust hidden state dimensions if needed\n",
        "    enc_layers = model.config['num_encoding_layers']\n",
        "    dec_layers = model.config['num_decoding_layers']\n",
        "    hidden_size = model.config['hidden_dim']\n",
        "    batch_size = 1\n",
        "\n",
        "    if enc_layers != dec_layers:\n",
        "        if model.cell_type != 'lstm':\n",
        "            if enc_layers > dec_layers:\n",
        "                hidden = hidden[:dec_layers]\n",
        "            else:\n",
        "                padding = torch.zeros(dec_layers - enc_layers, batch_size, hidden_size).to(device)\n",
        "                hidden = torch.cat([hidden, padding], dim=0)\n",
        "        else:  # LSTM case\n",
        "            if enc_layers > dec_layers:\n",
        "                hidden = hidden[:dec_layers]\n",
        "                cell = cell[:dec_layers]\n",
        "            else:\n",
        "                padding = torch.zeros(dec_layers - enc_layers, batch_size, hidden_size).to(device)\n",
        "                hidden = torch.cat([hidden, padding], dim=0)\n",
        "                cell = torch.cat([cell, padding], dim=0)\n",
        "\n",
        "    # Step 2.6: Start decoding with <SOS> token\n",
        "    trg_idx = [tgt_vocab['<SOS>']]\n",
        "    gradient_list = []\n",
        "\n",
        "    # Step 2.7: Generate translation and compute gradients\n",
        "    for _ in range(max_len):\n",
        "        # Clear previous gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Get current decoder input\n",
        "        trg_tensor = torch.LongTensor([trg_idx[-1]]).to(device)\n",
        "\n",
        "        # Forward pass through decoder\n",
        "        if hasattr(model, 'decoder') and hasattr(model.decoder, 'attention'):\n",
        "            # For attention model\n",
        "            output, hidden, cell, _ = model.decoder(trg_tensor, hidden, cell, encoder_outputs)\n",
        "        else:\n",
        "            # For vanilla model\n",
        "            if model.cell_type == \"lstm\":\n",
        "                output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "            else:\n",
        "                output, hidden = model.decoder(trg_tensor, hidden)\n",
        "                cell = None\n",
        "\n",
        "        # Get predicted token\n",
        "        pred_token = output.argmax(1).item()\n",
        "\n",
        "        # Step 2.8: Compute gradients with respect to the predicted token\n",
        "        # This implements the formula: ||∂(h^L_t̃)_k / ∂x_t||^2\n",
        "        output[0, pred_token].backward(retain_graph=True)\n",
        "\n",
        "        # Step 2.9: Get gradients for embedding\n",
        "        if src_emb.grad is not None:\n",
        "            # Sum across embedding dimension and square (for magnitude)\n",
        "            grad_magnitude = src_emb.grad.pow(2).sum(dim=2).squeeze(0).detach().cpu().numpy()\n",
        "            gradient_list.append(grad_magnitude)\n",
        "        else:\n",
        "            # Fallback if no gradients\n",
        "            gradient_list.append(np.ones(len(src_indices)) / len(src_indices))\n",
        "\n",
        "        # Step 2.10: Reset gradients for next iteration\n",
        "        if src_emb.grad is not None:\n",
        "            src_emb.grad.zero_()\n",
        "\n",
        "        # Stop if <EOS> token\n",
        "        if pred_token == tgt_vocab['<EOS>']:\n",
        "            break\n",
        "\n",
        "        trg_idx.append(pred_token)\n",
        "\n",
        "    # Step 2.11: Convert indices to characters\n",
        "    trg_tokens = [idx2tgt[i] for i in trg_idx if i not in [tgt_vocab['<SOS>'], tgt_vocab['<EOS>'], tgt_vocab['<PAD>']]]\n",
        "    translation = ''.join(trg_tokens)\n",
        "\n",
        "    # Step 2.12: Create connectivity matrix\n",
        "    connectivity = np.zeros((len(trg_tokens), len(src_text)))\n",
        "    for i, grad in enumerate(gradient_list[:len(trg_tokens)]):\n",
        "        if i < len(trg_tokens):\n",
        "            connectivity[i, :len(src_text)] = grad[:len(src_text)]\n",
        "            # Normalize each row\n",
        "            if np.sum(connectivity[i]) > 0:\n",
        "                connectivity[i] = connectivity[i] / np.max(connectivity[i])\n",
        "\n",
        "    return translation, connectivity\n"
      ],
      "metadata": {
        "id": "XwEPjlcmaicv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Bokeh if needed\n",
        "!pip install bokeh -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, ColorBar\n",
        "from bokeh.layouts import column, row, gridplot\n",
        "from bokeh.palettes import Viridis256, Reds256\n",
        "from bokeh.io import output_file, save\n",
        "from bokeh.models import CustomJS, TapTool"
      ],
      "metadata": {
        "id": "IKydvBpjbtJ2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bokeh_character_boxes_plot(model, src_text, src_vocab, tgt_vocab, idx2tgt):\n",
        "    \"\"\"\n",
        "    Create an interactive plot with character boxes:\n",
        "    - Output characters in boxes on top row\n",
        "    - Input characters in boxes on bottom row\n",
        "    - Hovering over output boxes highlights input boxes based on connectivity\n",
        "    - No tooltips displayed\n",
        "    \"\"\"\n",
        "    output_notebook()\n",
        "\n",
        "    # Step 1: Compute connectivity\n",
        "    translation, connectivity = compute_gradient_connectivity(model, src_text, src_vocab, tgt_vocab, idx2tgt)\n",
        "\n",
        "    # Step 2: Prepare data for character boxes\n",
        "    src_chars = list(src_text)\n",
        "    tgt_chars = list(translation)\n",
        "\n",
        "    # Create data sources for output and input characters\n",
        "    output_data = {\n",
        "        'x': list(range(len(tgt_chars))),\n",
        "        'y': [0] * len(tgt_chars),\n",
        "        'char': tgt_chars,\n",
        "        'index': list(range(len(tgt_chars)))\n",
        "    }\n",
        "    output_source = ColumnDataSource(data=output_data)\n",
        "\n",
        "    input_data = {\n",
        "        'x': list(range(len(src_chars))),\n",
        "        'y': [0] * len(src_chars),\n",
        "        'char': src_chars,\n",
        "        'color': ['#e6e6e6'] * len(src_chars),  # Light gray default\n",
        "        'alpha': [1.0] * len(src_chars)\n",
        "    }\n",
        "    input_source = ColumnDataSource(data=input_data)\n",
        "\n",
        "    # Step 3: Create the figures for output and input boxes\n",
        "    # Output character boxes (top)\n",
        "    output_plot = figure(\n",
        "        title=\"Output Characters (Devanagari)\",\n",
        "        x_range=(-0.5, len(tgt_chars) - 0.5),\n",
        "        y_range=(-0.5, 0.5),\n",
        "        width=600, height=100,\n",
        "        tools=\"hover\",\n",
        "        toolbar_location=None\n",
        "    )\n",
        "\n",
        "    # Input character boxes (bottom)\n",
        "    input_plot = figure(\n",
        "        title=\"Input Characters (Latin)\",\n",
        "        x_range=(-0.5, len(src_chars) - 0.5),\n",
        "        y_range=(-0.5, 0.5),\n",
        "        width=600, height=100,\n",
        "        tools=\"\",\n",
        "        toolbar_location=None\n",
        "    )\n",
        "\n",
        "    # Step 4: Add character boxes as rectangles\n",
        "    # Output boxes\n",
        "    output_rect = output_plot.rect(\n",
        "        x='x', y='y', width=0.9, height=0.9,\n",
        "        source=output_source,\n",
        "        fill_color=\"#64b5f6\",  # Light blue\n",
        "        line_color=\"black\",\n",
        "        line_width=2\n",
        "    )\n",
        "\n",
        "    # Output text\n",
        "    output_text = output_plot.text(\n",
        "        x='x', y='y', text='char',\n",
        "        source=output_source,\n",
        "        text_align=\"center\",\n",
        "        text_baseline=\"middle\",\n",
        "        text_font_size=\"16px\"\n",
        "    )\n",
        "\n",
        "    # Input boxes\n",
        "    input_rect = input_plot.rect(\n",
        "        x='x', y='y', width=0.9, height=0.9,\n",
        "        source=input_source,\n",
        "        fill_color='color',\n",
        "        line_color=\"black\",\n",
        "        line_width=2\n",
        "    )\n",
        "\n",
        "    # Input text\n",
        "    input_text = input_plot.text(\n",
        "        x='x', y='y', text='char',\n",
        "        source=input_source,\n",
        "        text_align=\"center\",\n",
        "        text_baseline=\"middle\",\n",
        "        text_font_size=\"16px\"\n",
        "    )\n",
        "\n",
        "    # Step 5: Add hover tool for output boxes with no tooltips\n",
        "    hover_tool = HoverTool(\n",
        "        renderers=[output_rect],\n",
        "        tooltips=None,  # Set tooltips to None to hide them\n",
        "        callback=CustomJS(args=dict(\n",
        "            input_source=input_source,\n",
        "            connectivity=connectivity.tolist()\n",
        "        ), code=\"\"\"\n",
        "            // Get the index of the hovered output character\n",
        "            const index = cb_data.index.indices[0];\n",
        "            if (index !== undefined) {\n",
        "                // Get connectivity values for this output character\n",
        "                const conn_row = connectivity[index];\n",
        "\n",
        "                // Update input box colors based on connectivity\n",
        "                const colors = input_source.data['color'];\n",
        "\n",
        "                for (let i = 0; i < colors.length; i++) {\n",
        "                    // Get connectivity value\n",
        "                    const weight = conn_row[i];\n",
        "\n",
        "                    // Create color based on weight (white to red gradient)\n",
        "                    const r = 255;\n",
        "                    const g = Math.max(0, Math.round(255 * (1 - weight)));\n",
        "                    const b = Math.max(0, Math.round(255 * (1 - weight)));\n",
        "\n",
        "                    colors[i] = `rgb(${r}, ${g}, ${b})`;\n",
        "                }\n",
        "\n",
        "                // Notify of data change\n",
        "                input_source.change.emit();\n",
        "            }\n",
        "        \"\"\")\n",
        "    )\n",
        "    output_plot.add_tools(hover_tool)\n",
        "\n",
        "    # Step 6: Remove grid lines and axes\n",
        "    output_plot.grid.grid_line_color = None\n",
        "    output_plot.axis.visible = False\n",
        "    input_plot.grid.grid_line_color = None\n",
        "    input_plot.axis.visible = False\n",
        "\n",
        "    # Step 7: Create layout\n",
        "    layout = column(\n",
        "        output_plot,\n",
        "        input_plot,\n",
        "        sizing_mode=\"stretch_width\"\n",
        "    )\n",
        "\n",
        "    return layout"
      ],
      "metadata": {
        "id": "oaSCa5XldLSV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'input_vocab_size': 30, 'output_vocab_size': 67, 'embedding_dim': 128, 'hidden_dim': 512, 'num_encoding_layers': 2, 'num_decoding_layers': 3, 'dropout': 0.3, 'cell_type': 'lstm', 'teacher_forcing_ratio': 0.9, 'learning_rate': 0.0006293179845087059, 'batch_size': 128}"
      ],
      "metadata": {
        "id": "uLyPHHJwa3YP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AttentionSeq2Seq(config).to(device)"
      ],
      "metadata": {
        "id": "XhqIRtnaaxuN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/best_attention_model.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXp9hoZdbMl1",
        "outputId": "6c589dea-481f-4dc8-9eeb-244b01a5791e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_viz = create_bokeh_character_boxes_plot(model, \"ankganit\", src_vocab, tgt_vocab, idx2tgt)\n",
        "show(interactive_viz)"
      ],
      "metadata": {
        "id": "6Z1-YBh8dfs8",
        "outputId": "fc2f927b-67a7-49ac-c6a2-deba417e1e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "'use strict';\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  const force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "const JS_MIME_TYPE = 'application/javascript';\n",
              "  const HTML_MIME_TYPE = 'text/html';\n",
              "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    const script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    function drop(id) {\n",
              "      const view = Bokeh.index.get_by_id(id)\n",
              "      if (view != null) {\n",
              "        view.model.document.clear()\n",
              "        Bokeh.index.delete(view)\n",
              "      }\n",
              "    }\n",
              "\n",
              "    const cell = handle.cell;\n",
              "\n",
              "    const id = cell.output_area._bokeh_element_id;\n",
              "    const server_id = cell.output_area._bokeh_server_id;\n",
              "\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null) {\n",
              "      drop(id)\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd_clean, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            const id = msg.content.text.trim()\n",
              "            drop(id)\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd_destroy);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    const output_area = handle.output_area;\n",
              "    const output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      const bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      const script_attrs = bk_div.children[0].attributes;\n",
              "      for (let i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      const toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    const events = require('base/js/events');\n",
              "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded(error = null) {\n",
              "    const el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      const html = (() => {\n",
              "        if (typeof root.Bokeh === \"undefined\") {\n",
              "          if (error == null) {\n",
              "            return \"BokehJS is loading ...\";\n",
              "          } else {\n",
              "            return \"BokehJS failed to load.\";\n",
              "          }\n",
              "        } else {\n",
              "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
              "          if (error == null) {\n",
              "            return `${prefix} successfully loaded.`;\n",
              "          } else {\n",
              "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
              "          }\n",
              "        }\n",
              "      })();\n",
              "      el.innerHTML = html;\n",
              "\n",
              "      if (error != null) {\n",
              "        const wrapper = document.createElement(\"div\");\n",
              "        wrapper.style.overflow = \"auto\";\n",
              "        wrapper.style.height = \"5em\";\n",
              "        wrapper.style.resize = \"vertical\";\n",
              "        const content = document.createElement(\"div\");\n",
              "        content.style.fontFamily = \"monospace\";\n",
              "        content.style.whiteSpace = \"pre-wrap\";\n",
              "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
              "        content.textContent = error.stack ?? error.toString();\n",
              "        wrapper.append(content);\n",
              "        el.append(wrapper);\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(() => display_loaded(error), 100);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error(url) {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.3.min.js\"];\n",
              "  const css_urls = [];\n",
              "\n",
              "  const inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      try {\n",
              "            for (let i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "\n",
              "      } catch (error) {throw error;\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"a64d5c6b-871b-4db0-951a-dd187f05583c\" data-root-id=\"p1942\" style=\"display: contents;\"></div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "  const docs_json = {\"a3684663-a0cb-46af-bccf-8a557ed3cd6f\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Column\",\"id\":\"p1942\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"children\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1855\",\"attributes\":{\"height\":100,\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1865\",\"attributes\":{\"start\":-0.5,\"end\":6.5}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1866\",\"attributes\":{\"start\":-0.5,\"end\":0.5}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1867\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1868\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1858\",\"attributes\":{\"text\":\"Output Characters (Devanagari)\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1910\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1849\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1850\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1851\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[0,1,2,3,4,5,6]],[\"y\",[0,0,0,0,0,0,0]],[\"char\",[\"\\u0905\",\"\\u0902\",\"\\u0915\",\"\\u0917\",\"\\u0923\",\"\\u093f\",\"\\u0924\"]],[\"index\",[0,1,2,3,4,5,6]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1911\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1912\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1907\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"height\":{\"type\":\"value\",\"value\":0.9},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#64b5f6\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1908\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"height\":{\"type\":\"value\",\"value\":0.9},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#64b5f6\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1909\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"height\":{\"type\":\"value\",\"value\":0.9},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#64b5f6\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1919\",\"attributes\":{\"data_source\":{\"id\":\"p1849\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1920\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1921\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Text\",\"id\":\"p1916\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"char\"},\"text_color\":{\"type\":\"value\",\"value\":\"black\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"16px\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"},\"text_baseline\":{\"type\":\"value\",\"value\":\"middle\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Text\",\"id\":\"p1917\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"char\"},\"text_color\":{\"type\":\"value\",\"value\":\"black\"},\"text_alpha\":{\"type\":\"value\",\"value\":0.1},\"text_font_size\":{\"type\":\"value\",\"value\":\"16px\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"},\"text_baseline\":{\"type\":\"value\",\"value\":\"middle\"}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Text\",\"id\":\"p1918\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"char\"},\"text_color\":{\"type\":\"value\",\"value\":\"black\"},\"text_alpha\":{\"type\":\"value\",\"value\":0.2},\"text_font_size\":{\"type\":\"value\",\"value\":\"16px\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"},\"text_baseline\":{\"type\":\"value\",\"value\":\"middle\"}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1864\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1879\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1941\",\"attributes\":{\"renderers\":[{\"id\":\"p1910\"}],\"callback\":{\"type\":\"object\",\"name\":\"CustomJS\",\"id\":\"p1940\",\"attributes\":{\"args\":{\"type\":\"map\",\"entries\":[[\"input_source\",{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1852\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1853\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1854\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[0,1,2,3,4,5,6,7]],[\"y\",[0,0,0,0,0,0,0,0]],[\"char\",[\"a\",\"n\",\"k\",\"g\",\"a\",\"n\",\"i\",\"t\"]],[\"color\",[\"#e6e6e6\",\"#e6e6e6\",\"#e6e6e6\",\"#e6e6e6\",\"#e6e6e6\",\"#e6e6e6\",\"#e6e6e6\",\"#e6e6e6\"]],[\"alpha\",[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]]]}}}],[\"connectivity\",[[0.03977124356348384,0.06106700997738375,0.42782702657086225,0.6073364391951616,1.0,0.0748660052230546,0.10542959236011332,0.06565659480803453],[0.038353983592998436,0.04942328133495472,0.25998973498782046,1.0,0.6718324070282038,0.09776303446289163,0.11276635049097317,0.046513105216744795],[0.018303329467766416,0.020773913948999054,0.1346608883304355,0.516841364832681,1.0,0.05138775079216899,0.04712113418386541,0.03749354045441154],[0.0026017625046479793,0.004155106078984414,0.10148854291535969,0.23988702753516808,1.0,0.034502632403633944,0.05093769708944118,0.04525161816716406],[0.02358539594939718,0.046320626447335006,0.34939120545190927,0.8047008966874754,1.0,0.07063098210208756,0.20072840488782281,0.10451444470798471],[0.02590179531617107,0.030411173128547086,0.4266147469652982,0.5958407146756401,1.0,0.10859687273748905,0.44224805522488986,0.2566972221401751],[0.011400773664326635,0.016098482111908136,0.06638650970388225,0.35258469701798584,1.0,0.07363500241619395,0.3013431268627174,0.1717320732895651]]]]},\"code\":\"\\n            // Get the index of the hovered output character\\n            const index = cb_data.index.indices[0];\\n            if (index !== undefined) {\\n                // Get connectivity values for this output character\\n                const conn_row = connectivity[index];\\n\\n                // Update input box colors based on connectivity\\n                const colors = input_source.data['color'];\\n\\n                for (let i = 0; i < colors.length; i++) {\\n                    // Get connectivity value\\n                    const weight = conn_row[i];\\n\\n                    // Create color based on weight (white to red gradient)\\n                    const r = 255;\\n                    const g = Math.max(0, Math.round(255 * (1 - weight)));\\n                    const b = Math.max(0, Math.round(255 * (1 - weight)));\\n\\n                    colors[i] = `rgb(${r}, ${g}, ${b})`;\\n                }\\n\\n                // Notify of data change\\n                input_source.change.emit();\\n            }\\n        \"}},\"tooltips\":null}}]}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1874\",\"attributes\":{\"visible\":false,\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1875\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1876\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1877\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1869\",\"attributes\":{\"visible\":false,\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1870\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1871\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1872\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1873\",\"attributes\":{\"axis\":{\"id\":\"p1869\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1878\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1874\"},\"grid_line_color\":null}}]}},{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1880\",\"attributes\":{\"height\":100,\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1890\",\"attributes\":{\"start\":-0.5,\"end\":7.5}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1891\",\"attributes\":{\"start\":-0.5,\"end\":0.5}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1892\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1893\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1883\",\"attributes\":{\"text\":\"Input Characters (Latin)\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1928\",\"attributes\":{\"data_source\":{\"id\":\"p1852\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1929\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1930\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1925\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"height\":{\"type\":\"value\",\"value\":0.9},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1926\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"height\":{\"type\":\"value\",\"value\":0.9},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Rect\",\"id\":\"p1927\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"width\":{\"type\":\"value\",\"value\":0.9},\"height\":{\"type\":\"value\",\"value\":0.9},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1937\",\"attributes\":{\"data_source\":{\"id\":\"p1852\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1938\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1939\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Text\",\"id\":\"p1934\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"char\"},\"text_color\":{\"type\":\"value\",\"value\":\"black\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"16px\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"},\"text_baseline\":{\"type\":\"value\",\"value\":\"middle\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Text\",\"id\":\"p1935\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"char\"},\"text_color\":{\"type\":\"value\",\"value\":\"black\"},\"text_alpha\":{\"type\":\"value\",\"value\":0.1},\"text_font_size\":{\"type\":\"value\",\"value\":\"16px\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"},\"text_baseline\":{\"type\":\"value\",\"value\":\"middle\"}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Text\",\"id\":\"p1936\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"char\"},\"text_color\":{\"type\":\"value\",\"value\":\"black\"},\"text_alpha\":{\"type\":\"value\",\"value\":0.2},\"text_font_size\":{\"type\":\"value\",\"value\":\"16px\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"},\"text_baseline\":{\"type\":\"value\",\"value\":\"middle\"}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1889\"},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1899\",\"attributes\":{\"visible\":false,\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1900\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1901\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1902\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1894\",\"attributes\":{\"visible\":false,\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1895\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1896\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1897\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1898\",\"attributes\":{\"axis\":{\"id\":\"p1894\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1903\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1899\"},\"grid_line_color\":null}}]}}]}}]}};\n",
              "  const render_items = [{\"docid\":\"a3684663-a0cb-46af-bccf-8a557ed3cd6f\",\"roots\":{\"p1942\":\"a64d5c6b-871b-4db0-951a-dd187f05583c\"},\"root_ids\":[\"p1942\"]}];\n",
              "  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    let attempts = 0;\n",
              "    const timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "p1942"
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from bokeh.io import save, output_file\n",
        "\n",
        "def log_interactive_plot_to_wandb(model, src_text, src_vocab, tgt_vocab, idx2tgt, run=None):\n",
        "    \"\"\"\n",
        "    Create an interactive connectivity plot and log it to Weights & Biases.\n",
        "\n",
        "    Args:\n",
        "        model: Your transliteration model\n",
        "        src_text: Source text (Latin characters)\n",
        "        src_vocab: Source vocabulary mapping\n",
        "        tgt_vocab: Target vocabulary mapping\n",
        "        idx2tgt: Mapping from indices to target characters\n",
        "        run: Optional wandb run object (if None, uses current run)\n",
        "    \"\"\"\n",
        "    # Create the interactive plot\n",
        "    interactive_plot = create_bokeh_character_boxes_plot(model, src_text, src_vocab, tgt_vocab, idx2tgt)\n",
        "\n",
        "    # Save the plot to an HTML file\n",
        "    output_file(f\"connectivity_plot_{src_text}.html\")\n",
        "    save(interactive_plot)\n",
        "\n",
        "    # Initialize W&B if not already initialized\n",
        "    if run is None and wandb.run is None:\n",
        "        wandb.init(project=\"seq2seq-attention-transliteration\")\n",
        "\n",
        "    # Log the HTML file to W&B\n",
        "    if run:\n",
        "        run.log({f\"connectivity_{src_text}\": wandb.Html(f\"connectivity_plot_{src_text}.html\")})\n",
        "    else:\n",
        "        wandb.log({f\"connectivity_{src_text}\": wandb.Html(f\"connectivity_plot_{src_text}.html\")})\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    print(f\"Interactive plot for '{src_text}' saved to W&B\")"
      ],
      "metadata": {
        "id": "I1C8SjVCdoFN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_interactive_plot_to_wandb(model, \"ankur\", src_vocab, tgt_vocab, idx2tgt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "sssIYZfpdrHC",
        "outputId": "1803371e-f873-450b-c066-cb85e297472c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250521_110029-8scdtf7u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration/runs/8scdtf7u' target=\"_blank\">lilac-yogurt-49</a></strong> to <a href='https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration' target=\"_blank\">https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration/runs/8scdtf7u' target=\"_blank\">https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration/runs/8scdtf7u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lilac-yogurt-49</strong> at: <a href='https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration/runs/8scdtf7u' target=\"_blank\">https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration/runs/8scdtf7u</a><br> View project at: <a href='https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration' target=\"_blank\">https://wandb.ai/da24m005-iit-madras/seq2seq-attention-transliteration</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250521_110029-8scdtf7u/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive plot for 'ankur' saved to W&B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbEaz5bBdyZy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}